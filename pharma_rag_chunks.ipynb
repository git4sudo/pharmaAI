{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git4sudo/pharmaAI/blob/main/pharma_rag_chunks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ed4gnnMnMd7O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import uuid\n",
        "from typing import List, Dict, Any\n",
        "import re\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei0KF8OxPGce",
        "outputId": "ab916964-a74d-45c4-fc1e-2114a5462cf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path='/content/drive/MyDrive/pharmadata/Cleaned_MID_csv_copy.csv'"
      ],
      "metadata": {
        "id": "VMUfD5UHPs1X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(csv_file_path):\n",
        "    print(f\"✅ Found CSV file: {os.path.basename(csv_file_path)}\")\n",
        "    print(f\"📁 Full path: {csv_file_path}\")\n",
        "\n",
        "    # Get file size\n",
        "    file_size = os.path.getsize(csv_file_path)\n",
        "    print(f\"📊 File size: {file_size} bytes ({file_size/1024:.1f} KB)\")\n",
        "else:\n",
        "    print(f\"❌ CSV file not found at: {csv_file_path}\")\n",
        "    print(\"💡 Make sure the file path is correct and the file exists in your Google Drive\")\n",
        "    exit()\n",
        "\n",
        "print(f\"🎯 Using CSV file: {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMLjmsd0M594",
        "outputId": "0dc50380-14a2-4639-bda0-4f7f8dd5c77a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found CSV file: Cleaned_MID_csv_copy.csv\n",
            "📁 Full path: /content/drive/MyDrive/pharmadata/Cleaned_MID_csv_copy.csv\n",
            "📊 File size: 699360895 bytes (682969.6 KB)\n",
            "🎯 Using CSV file: /content/drive/MyDrive/pharmadata/Cleaned_MID_csv_copy.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PharmaceuticalRAGConverter:\n",
        "    def __init__(self, csv_file_path):\n",
        "        self.df = pd.read_csv(csv_file_path)\n",
        "        # Clean column names\n",
        "        self.df.columns = self.df.columns.str.strip()\n",
        "        self.processed_chunks = []\n",
        "        print(f\"✅ Loaded CSV with {len(self.df)} rows and {len(self.df.columns)} columns\")\n",
        "        print(f\"📋 Columns: {list(self.df.columns)}\")\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        if pd.isna(text) or text == '':\n",
        "            return \"\"\n",
        "        text = str(text)\n",
        "        text = ' '.join(text.split())\n",
        "        text = re.sub(r'[^\\w\\s\\-\\.\\(\\)\\[\\]\\,\\;\\:]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    def create_focused_chunks(self, row: pd.Series, row_idx: int) -> List[Dict[str, Any]]:\n",
        "        drug_name = self.clean_text(row.get('Name', ''))\n",
        "        contains = self.clean_text(row.get('Contains', ''))\n",
        "        chunks = []\n",
        "\n",
        "        base_metadata = {\n",
        "            \"source_type\": \"CSV_pharmaceutical_database\",\n",
        "            \"drug_name\": drug_name,\n",
        "            \"active_ingredient\": contains,\n",
        "            \"row_index\": row_idx\n",
        "        }\n",
        "\n",
        "        # 1. Basic Information Chunk\n",
        "        basic_info_parts = []\n",
        "        if drug_name:\n",
        "            basic_info_parts.append(f\"{drug_name}\")\n",
        "        if contains:\n",
        "            basic_info_parts.append(f\"contains {contains}\")\n",
        "\n",
        "        # Get product info from different possible columns\n",
        "        product_info_columns = ['ProductInfo', 'ProductUsage', 'ProductUse']\n",
        "        product_info = \"\"\n",
        "        for col in product_info_columns:\n",
        "            if col in row:\n",
        "                product_info = self.clean_text(row.get(col, ''))\n",
        "                if product_info:\n",
        "                    break\n",
        "\n",
        "        if product_info:\n",
        "            basic_info_parts.append(f\"Product details: {product_info}\")\n",
        "\n",
        "        if basic_info_parts:\n",
        "            text_chunk = \". \".join(basic_info_parts)\n",
        "            chunks.append({\n",
        "                \"text_chunk\": text_chunk,\n",
        "                \"metadata\": {\n",
        "                    **base_metadata,\n",
        "                    \"source_id\": f\"drug_db_{drug_name.lower().replace(' ', '_')}_basic_{row_idx}\",\n",
        "                    \"topic\": \"basic_information\"\n",
        "                }\n",
        "            })\n",
        "\n",
        "        # 2. Usage and Dosage Chunk\n",
        "        usage_parts = []\n",
        "\n",
        "        # Check different possible column names for usage info\n",
        "        usage_columns = ['HowToUse', 'HowToUse', 'Usage', 'Dosage']\n",
        "        for col in usage_columns:\n",
        "            if col in row:\n",
        "                usage_info = self.clean_text(row.get(col, ''))\n",
        "                if usage_info:\n",
        "                    usage_parts.append(f\"Instructions: {usage_info}\")\n",
        "                    break\n",
        "\n",
        "        if usage_parts:\n",
        "            text_chunk = \". \".join(usage_parts)\n",
        "            chunks.append({\n",
        "                \"text_chunk\": text_chunk,\n",
        "                \"metadata\": {\n",
        "                    **base_metadata,\n",
        "                    \"source_id\": f\"drug_db_{drug_name.lower().replace(' ', '_')}_usage_{row_idx}\",\n",
        "                    \"topic\": \"dosage_and_usage\"\n",
        "                }\n",
        "            })\n",
        "\n",
        "        # 3. Safety and Side Effects Chunk\n",
        "        safety_parts = []\n",
        "\n",
        "        side_effects_columns = ['SideEffects', 'SideEffect', 'Warnings']\n",
        "        for col in side_effects_columns:\n",
        "            if col in row:\n",
        "                side_effects = self.clean_text(row.get(col, ''))\n",
        "                if side_effects:\n",
        "                    safety_parts.append(f\"Side Effects: {side_effects}\")\n",
        "                    break\n",
        "\n",
        "        safety_columns = ['SafetyAdvice', 'Safety', 'Precautions']\n",
        "        for col in safety_columns:\n",
        "            if col in row:\n",
        "                safety_advice = self.clean_text(row.get(col, ''))\n",
        "                if safety_advice:\n",
        "                    safety_parts.append(f\"Safety Advice: {safety_advice}\")\n",
        "                    break\n",
        "\n",
        "        habit_columns = ['Chemical_Habit_Forming', 'HabitForming', 'Habit_Forming']\n",
        "        for col in habit_columns:\n",
        "            if col in row:\n",
        "                habit_forming = self.clean_text(row.get(col, ''))\n",
        "                if habit_forming and habit_forming.upper() not in ['FALSE', 'NO', '0']:\n",
        "                    safety_parts.append(f\"Habit Forming: {habit_forming}\")\n",
        "                    break\n",
        "\n",
        "        if safety_parts:\n",
        "            text_chunk = \". \".join(safety_parts)\n",
        "            chunks.append({\n",
        "                \"text_chunk\": text_chunk,\n",
        "                \"metadata\": {\n",
        "                    **base_metadata,\n",
        "                    \"source_id\": f\"drug_db_{drug_name.lower().replace(' ', '_')}_safety_{row_idx}\",\n",
        "                    \"topic\": \"safety_and_side_effects\"\n",
        "                }\n",
        "            })\n",
        "\n",
        "        # 4. Classification Chunk\n",
        "        classification_parts = []\n",
        "\n",
        "        therapeutic_columns = ['Therapeutic_Class', 'TherapeuticClass', 'Therapeut_Class']\n",
        "        for col in therapeutic_columns:\n",
        "            if col in row:\n",
        "                therapeutic_class = self.clean_text(row.get(col, ''))\n",
        "                if therapeutic_class:\n",
        "                    classification_parts.append(f\"Therapeutic Class: {therapeutic_class}\")\n",
        "                    break\n",
        "\n",
        "        action_columns = ['Action_Class', 'ActionClass', 'Action__Class']\n",
        "        for col in action_columns:\n",
        "            if col in row:\n",
        "                action_class = self.clean_text(row.get(col, ''))\n",
        "                if action_class:\n",
        "                    classification_parts.append(f\"Action Class: {action_class}\")\n",
        "                    break\n",
        "\n",
        "        if classification_parts:\n",
        "            text_chunk = \". \".join(classification_parts)\n",
        "            chunks.append({\n",
        "                \"text_chunk\": text_chunk,\n",
        "                \"metadata\": {\n",
        "                    **base_metadata,\n",
        "                    \"source_id\": f\"drug_db_{drug_name.lower().replace(' ', '_')}_classification_{row_idx}\",\n",
        "                    \"topic\": \"drug_classification\"\n",
        "                }\n",
        "            })\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def process_csv_to_rag(self) -> List[Dict[str, Any]]:\n",
        "        all_chunks = []\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            try:\n",
        "                chunks = self.create_focused_chunks(row, idx)\n",
        "                for chunk in chunks:\n",
        "                    if chunk[\"text_chunk\"].strip():\n",
        "                        all_chunks.append(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error processing row {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        self.processed_chunks = all_chunks\n",
        "        print(f\"✅ Processed {len(all_chunks)} chunks\")\n",
        "        return all_chunks\n",
        "\n",
        "    def preview_chunks(self, num_chunks: int = 3):\n",
        "        if not self.processed_chunks:\n",
        "            print(\"❌ No processed chunks available.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n📋 Preview of first {min(num_chunks, len(self.processed_chunks))} chunks:\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, chunk in enumerate(self.processed_chunks[:num_chunks]):\n",
        "            print(f\"\\n🔸 Chunk {i+1}:\")\n",
        "            print(f\"Text: {chunk['text_chunk']}\")\n",
        "            print(f\"Metadata: {json.dumps(chunk['metadata'], indent=2)}\")\n",
        "            print(\"-\" * 60)\n"
      ],
      "metadata": {
        "id": "ugcNV4PFM9QV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = PharmaceuticalRAGConverter(csv_file_path)"
      ],
      "metadata": {
        "id": "zF_daIDbNSVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da022b6b-3484-482d-c3f9-d69ab55cf04c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded CSV with 148272 rows and 14 columns\n",
            "📋 Columns: ['Name', 'Contains', 'ProductIntroduction', 'ProductUses', 'ProductBenefits', 'SideEffect', 'HowToUse', 'HowWorks', 'QuickTips', 'SafetyAdvice', 'Chemical_Class', 'Habit_Forming', 'Therapeutic_Class', 'Action_Class']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🔄 Processing CSV to RAG format...\")\n",
        "rag_chunks = converter.process_csv_to_rag()"
      ],
      "metadata": {
        "id": "-o1_u6zwNSRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36aa685a-1175-4808-d042-789aafc37244"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Processing CSV to RAG format...\n",
            "✅ Processed 593000 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter.preview_chunks(3)"
      ],
      "metadata": {
        "id": "I2VkBPc0NSOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3fe203-e00f-44d4-a537-1c5aeaaf5d5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📋 Preview of first 3 chunks:\n",
            "================================================================================\n",
            "\n",
            "🔸 Chunk 1:\n",
            "Text: andol 0.5mg tablet. contains haloperidol (0.5mg)\n",
            "Metadata: {\n",
            "  \"source_type\": \"CSV_pharmaceutical_database\",\n",
            "  \"drug_name\": \"andol 0.5mg tablet\",\n",
            "  \"active_ingredient\": \"haloperidol (0.5mg)\",\n",
            "  \"row_index\": 0,\n",
            "  \"source_id\": \"drug_db_andol_0.5mg_tablet_basic_0\",\n",
            "  \"topic\": \"basic_information\"\n",
            "}\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔸 Chunk 2:\n",
            "Text: Instructions: take this medicine in the dose and duration as advised by your doctor. swallow it as a whole. do not chew, crush or break it. andol 0.5mg tablet may be taken with or without food, but it is better to take it at a fixed time.\n",
            "Metadata: {\n",
            "  \"source_type\": \"CSV_pharmaceutical_database\",\n",
            "  \"drug_name\": \"andol 0.5mg tablet\",\n",
            "  \"active_ingredient\": \"haloperidol (0.5mg)\",\n",
            "  \"row_index\": 0,\n",
            "  \"source_id\": \"drug_db_andol_0.5mg_tablet_usage_0\",\n",
            "  \"topic\": \"dosage_and_usage\"\n",
            "}\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔸 Chunk 3:\n",
            "Text: Side Effects: most side effects do not require any medical attention and disappear as your body adjusts to the medicine. consult your doctor if they persist or if you re worried about them common side effects of andol agitation extrapyramidal symptoms insomnia (difficulty in sleeping) muscle spasm headache. Safety Advice: alcohol andol 0.5mg tablet may cause excessive drowsiness with alcohol. pregnancy andol 0.5mg tablet may be unsafe to use during pregnancy. although there are limited studies in humans animal studies have shown harmful effects on the developing baby. your doctor will weigh the benefits and any potential risks before prescribing it to you. please consult your doctor. breast feeding andol 0.5mg tablet is probably unsafe to use during breastfeeding. limited human data suggests that the drug may pass into the breastmilk and harm the baby.if andol 0.5mg tablet is used monitor the baby for excessive sleepiness. driving andol 0.5mg tablet may decrease alertness affect your vision or make you feel sleepy and dizzy. do not drive if these symptoms occur. kidney andol 0.5mg tablet is safe to use in patients with kidney disease. no dose adjustment of andol 0.5mg tablet is recommended.however patients with severe kidney disease may need to be started at a lower dose as it may cause excessive sleepiness in these patients. liver andol 0.5mg tablet should be used with caution in patients with liver disease. dose adjustment of andol 0.5mg tablet may be needed. please consult your doctor.\n",
            "Metadata: {\n",
            "  \"source_type\": \"CSV_pharmaceutical_database\",\n",
            "  \"drug_name\": \"andol 0.5mg tablet\",\n",
            "  \"active_ingredient\": \"haloperidol (0.5mg)\",\n",
            "  \"row_index\": 0,\n",
            "  \"source_id\": \"drug_db_andol_0.5mg_tablet_safety_0\",\n",
            "  \"topic\": \"safety_and_side_effects\"\n",
            "}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = {\n",
        "    \"total_chunks\": len(rag_chunks),\n",
        "    \"source_file\": os.path.basename(csv_file_path),\n",
        "    \"chunks\": rag_chunks\n",
        "}\n"
      ],
      "metadata": {
        "id": "0DXZsKP8NSL6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_filename = f\"pharmaceutical_rag_data.json\"\n",
        "with open(json_filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_data, f, indent=2, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "UA2nvZ5mNSBa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jsonl_filename = f\"pharmaceutical_rag_data.jsonl\"\n",
        "with open(jsonl_filename, 'w', encoding='utf-8') as f:\n",
        "    for chunk in rag_chunks:\n",
        "        json.dump(chunk, f, ensure_ascii=False)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "6BbXwTLHNfw4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"- {json_filename} (Complete JSON)\")\n",
        "print(f\"- {jsonl_filename} (JSONL format)\")"
      ],
      "metadata": {
        "id": "JMkpd7NzNfqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5510f6af-fc15-484a-e52f-32fcfcf5aef3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- pharmaceutical_rag_data.json (Complete JSON)\n",
            "- pharmaceutical_rag_data.jsonl (JSONL format)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n📊 Processing Statistics:\")\n",
        "print(f\"- Total drugs processed: {len(converter.df)}\")\n",
        "print(f\"- Total chunks created: {len(rag_chunks)}\")\n",
        "print(f\"- Average chunks per drug: {len(rag_chunks)/len(converter.df):.1f}\")"
      ],
      "metadata": {
        "id": "N2yGPGgFNfnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eeaedb1-91b2-4a29-962b-1cfecb87de50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Processing Statistics:\n",
            "- Total drugs processed: 148272\n",
            "- Total chunks created: 593000\n",
            "- Average chunks per drug: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_counts = {}\n",
        "for chunk in rag_chunks:\n",
        "    topic = chunk['metadata']['topic']\n",
        "    topic_counts[topic] = topic_counts.get(topic, 0) + 1"
      ],
      "metadata": {
        "id": "1q29K9MYNm57"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n📋 Chunks by Topic:\")\n",
        "for topic, count in topic_counts.items():\n",
        "    print(f\"- {topic}: {count} chunks\")"
      ],
      "metadata": {
        "id": "Heo75ntgNm2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8315fd-ad35-4aa6-c208-4ac85eb14978"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📋 Chunks by Topic:\n",
            "- basic_information: 148272 chunks\n",
            "- dosage_and_usage: 148197 chunks\n",
            "- safety_and_side_effects: 148259 chunks\n",
            "- drug_classification: 148272 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDSuyKCFNmyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UEjLfCNxNmt5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}